\documentclass[11pt,onecolumn]{article}

% Essential packages
\usepackage[utf8]{inputenc}
\usepackage[T1]{fontenc}
\usepackage{amsmath,amssymb}
\usepackage{graphicx}
\usepackage{booktabs}
\usepackage{hyperref}
\usepackage{cite}
\usepackage{algorithm}
\usepackage{algorithmic}
\usepackage{subcaption}
\usepackage{xcolor}
\usepackage{listings}

% Page layout
\usepackage[margin=1in]{geometry}

% Code listing style (for shader/API code snippets)
\lstset{
    basicstyle=\ttfamily\small,
    breaklines=true,
    frame=single,
    numbers=left,
    numberstyle=\tiny,
    commentstyle=\color{gray},
    keywordstyle=\color{blue},
}

% Hyperref setup
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    citecolor=blue,
    urlcolor=blue,
}

% Title and authors
\title{\textbf{Incremental Performance and Quality Analysis of Hybrid Ray Tracing: Vulkan vs DXR in Real-Time Rendering}}

\author{
    De Meyer Luca\\
    \textit{Howest - Digital Arts and Entertainment}\\
    \texttt{luca.de.meyer@student.howest.be}
}

\date{\today}

\begin{document}

\maketitle

\begin{abstract}
Real-time rendering is transitioning from pure rasterization to hybrid ray tracing, yet developers lack quantitative guidance on which ray-traced features to adopt first.
While shadows, reflections, and global illumination each offer visual improvements, their performance costs and perceptual quality gains remain poorly characterized
in production contexts. This study measures the incremental costs and visual quality of ray-traced shadows and reflections in Vulkan Ray Tracing and DirectX Raytracing
(DXR), identifying configurations that achieve 60 FPS on mid-range hardware. We evaluate multiple hybrid strategies including G-buffer-guided tracing, adaptive sampling,
and screen-space fallbacks across three representative scenes at 1080p and 1440p resolutions. Using perceptual metrics (LPIPS, SSIM) and GPU profiling, we quantify the
quality-per-millisecond ratio for each approach. Our results provide practical recommendations for incremental ray tracing adoption in real-time applications,
 demonstrating that [placeholder for key finding] achieves the optimal balance between visual fidelity and performance.
\end{abstract}

\section{Introduction}
\label{sec:introduction}

The advent of hardware-accelerated ray tracing in consumer GPUs (NVIDIA RTX 20-series and AMD RDNA 2) has transformed real-time rendering from a purely
rasterization-based paradigm to a hybrid approach combining traditional techniques with ray-traced effects. While full path-traced rendering remains computationally
prohibitive for interactive framerates, selective use of ray tracing for shadows, reflections, and ambient occlusion offers a practical middle ground between rasterization
artifacts and photorealistic quality.

However, adopting ray tracing incrementally presents a complex optimization problem. Each ray-traced feature incurs a measurable performance cost, yet the perceptual
quality improvement varies significantly based on scene characteristics, sampling strategies, and denoising techniques. Developers transitioning to hybrid rendering
face critical questions: Which features should be ray-traced first? What sampling rates are perceptually sufficient? How do different hybrid strategies compare
in quality-per-millisecond efficiency?

Existing benchmarks and research typically evaluate either full ray tracing pipelines or isolated techniques, leaving a gap in practical guidance for incremental
adoption. Furthermore, the performance parity between Vulkan Ray Tracing and DirectX Raytracing (DXR) remains under-documented, despite both APIs targeting the same
underlying hardware acceleration structures.

This study addresses these gaps through systematic experimentation across three representative scenes, measuring the individual and combined costs of ray-traced shadows
and reflections. We quantify visual quality using perceptual metrics (LPIPS, SSIM, PSNR) against path-traced ground truth and derive a quality-per-millisecond metric
to rank hybrid strategies. Our experiments span multiple resolutions, sampling rates, and optimization techniques on current RTX hardware.

\subsection{Contributions}
\label{subsec:contributions}

Our work makes the following contributions:

\begin{itemize}
    \item Quantitative measurement of incremental ray tracing costs for shadows and reflections individually and in combination
    \item Perceptual quality analysis of different sampling rates and denoising strategies using LPIPS, SSIM, and PSNR metrics
    \item Direct performance comparison of Vulkan Ray Tracing and DXR on identical hardware and workloads
    \item Quality-per-millisecond ranking of hybrid rendering strategies (G-buffer-guided, adaptive sampling, screen-space fallbacks)
    \item Practical configuration recommendations for achieving 60 FPS targets on mid-range RTX hardware
\end{itemize}

\section{Background and Related Work}
\label{sec:background}

\subsection{Ray Tracing Fundamentals}
\label{subsec:rt-fundamentals}

Ray tracing simulates light transport by casting rays from the camera through each pixel and testing for intersections with scene geometry. Modern hardware acceleration
structures (Bounding Volume Hierarchies) enable real-time traversal, though full path tracing remains expensive. Hybrid rendering selectively applies ray tracing to
effects where rasterization produces visible artifacts: hard shadows from small light sources, accurate reflections on curved surfaces, and inter-object occlusion.

\subsection{Vulkan Ray Tracing vs DirectX Raytracing}
\label{subsec:api-comparison}

Both Vulkan Ray Tracing (VK\_KHR\_ray\_tracing) and DirectX Raytracing (DXR) expose hardware ray tracing through similar abstractions: acceleration structures,
shader binding tables, and ray generation/intersection/miss shaders. Vulkan offers explicit control over memory and synchronization, while DXR provides higher-level
abstractions. Both compile to identical GPU instructions on NVIDIA and AMD hardware, leading to expectations of performance parity with minor driver overhead differences.

\subsection{Hybrid Rendering Strategies}
\label{subsec:hybrid-strategies}

Several hybrid approaches have emerged in production rendering:

\textbf{Full-screen ray tracing} dispatches rays for every pixel but uses low sample counts (1-2 SPP) with aggressive denoising.
 This is the most straightforward approach but potentially wasteful on pixels where screen-space techniques suffice.

\textbf{G-buffer-guided tracing} uses rasterized geometry buffers to selectively dispatch rays only where needed
 (e.g., on glossy surfaces for reflections or in shadow penumbrae). This reduces ray count but requires additional logic to determine ray spawn conditions.

\textbf{Screen-space first, ray-traced fallback} attempts cheaper screen-space techniques (SSR, SSAO) and only invokes ray tracing when screen-space fails
 (off-screen reflections, occluded regions). This minimizes ray tracing overhead but introduces complexity in blending techniques.

\textbf{Adaptive sampling} varies ray count per pixel based on material roughness, motion vectors, or edge detection. Smooth regions receive fewer samples while
 edges and specular highlights receive more, optimizing the sample budget.

Prior work has evaluated these strategies in isolation, but comprehensive quality-per-cost comparisons across multiple scenes and features remain limited.

\subsection{Perceptual Quality Metrics}
\label{subsec:quality-metrics}

Traditional image quality metrics like PSNR and SSIM capture structural differences but correlate weakly with human perception for rendered images. LPIPS (Learned Perceptual Image Patch Similarity) uses deep neural networks trained on human perceptual judgments, providing better correlation with subjective quality assessment. We employ all three metrics for comprehensive evaluation, with LPIPS as the primary perceptual measure.

\section{Research Questions and Hypotheses}
\label{sec:hypotheses}

We investigate the following research questions:

\begin{enumerate}
    \item What are the individual and combined performance costs of ray-traced shadows and reflections?
    \item How do these costs scale with resolution and scene complexity?
    \item Which hybrid strategies offer the best quality-per-millisecond ratio?
    \item Do Vulkan and DXR achieve performance parity on identical workloads?
\end{enumerate}

Based on preliminary profiling and prior literature, we formulate the following hypotheses:

\subsection{Performance Costs (H1)}

\textbf{H1a:} Ray-traced shadows cost less than reflections, with global illumination being most expensive. We expect shadows to add approximately 2ms, reflections 4-6ms, and combined features 7-9ms at 1080p on RTX 3060.

\textbf{H1b:} Rendering costs scale super-linearly with resolution due to increased ray coherence loss. We predict 1080p to 1440p incurs 1.8× cost, and 1440p to 4K incurs 2.2× cost.

\textbf{H1c:} Vulkan and DXR perform within ±5-10\% on identical hardware, as both compile to the same GPU ray tracing instructions with minor driver overhead differences.

\subsection{Quality Optimization (H2)}

\textbf{H2a:} One sample per pixel (1 SPP) with temporal denoising achieves superior visual quality per millisecond compared to 4 SPP without denoising, due to temporal accumulation effectively raising the sample count.

\textbf{H2b:} Adaptive sampling based on edge detection reduces cost by 40-60\% without perceptible quality loss, as most pixels require minimal sampling.

\textbf{H2c:} G-buffer-guided tracing provides the best quality-cost ratio, reducing cost by approximately 50\% with less than 10\% quality degradation.

\subsection{Hybrid Strategy Effectiveness (H3)}

We predict the following ranking by quality-per-millisecond:
\begin{enumerate}
    \item G-buffer guided + 1 SPP + temporal denoising
    \item Screen-space first with ray-traced fallback
    \item Adaptive sampling (motion/roughness based)
    \item Full-screen ray tracing with low samples
    \item Full-screen ray tracing with high samples
\end{enumerate}

\subsection{Scene Complexity Scaling (H4)}

\textbf{H4a:} Shadow costs scale linearly O(n) with light count. We expect 1 light: 2ms, 4 lights: 8ms.

\textbf{H4b:} Reflection costs scale logarithmically O(log n) with BVH depth. Doubling triangle count should increase cost by approximately 30\%, not 100\%.

\textbf{H4c:} Material complexity affects shading more than ray tracing overhead. Complex PBR shading should add approximately 2ms regardless of ray tracing usage.

\section{Methodology}
\label{sec:methodology}

\subsection{Experimental Design}
\label{subsec:experimental-design}

Our experiment measures incremental performance costs and visual quality improvements when transitioning from pure rasterization to hybrid ray tracing. We employ a controlled experimental design with systematic variation of rendering features, sampling strategies, and scene characteristics.

\subsection{Test Scenes}
\label{subsec:test-scenes}

Three representative scenes are selected to cover different performance and quality scenarios:

\textbf{Indoor Scene:} Medium geometric complexity (1-2M triangles) featuring several glossy materials and 2-3 dynamic light sources. This scene tests reflection accuracy on varied surface roughness and multi-light shadow performance.

\textbf{Outdoor Scene:} High geometric complexity (10M triangles) with vegetation, small occluders, and one dominant directional light. This scene stresses BVH traversal and tests shadow quality with complex occluder geometry.

\textbf{Specular Scene:} Low triangle count but multiple mirror and water-like surfaces. This scene isolates reflection quality and tests handling of highly reflective materials where screen-space techniques fail.

Each scene includes a scripted camera path ensuring reproducible viewpoints across all test runs. Ground-truth reference images are generated using 1024 SPP path tracing for perceptual quality comparison.

\subsection{Independent Variables}
\label{subsec:variables}

Table~\ref{tab:variables} summarizes the experimental variables tested in our study.

\begin{table*}[t]
\centering
\caption{Experimental Variables and Test Values}
\label{tab:variables}
\begin{tabular}{@{}lll@{}}
\toprule
\textbf{Category} & \textbf{Variable} & \textbf{Values Tested} \\
\midrule
Resolution & Internal rendering resolution & 1080p, 1440p \\
Ray-Traced Features & Enabled feature set & None, Shadows only, Reflections only, Both \\
Samples Per Pixel & Ray sample count & 1, 2, 4, 8 \\
Denoiser & Temporal/spatial filtering & None, Simple temporal, SVGF-like, NRD \\
Hybrid Strategy & Ray dispatch method & Full-screen, G-buffer guided, SSR fallback, Adaptive \\
Trace Resolution & RT buffer resolution & Full, Half, Quarter \\
Light Count & Active light sources & 1, 4, 8 \\
Scene Complexity & BVH size / geometry density & Base, 2× triangles, 4× triangles \\
\bottomrule
\end{tabular}
\end{table*}

\subsection{Hardware and Software Configuration}
\label{subsec:hardware-config}

Experiments are conducted on three representative hardware configurations:

\begin{itemize}
    \item \textbf{Mid-range laptop:} RTX 3060 Mobile (6GB), Ryzen 5800H, 16GB RAM
    \item \textbf{High-end laptop:} RTX 4090 Mobile (16GB), i9-13980HX, 32GB RAM
    \item \textbf{Desktop:} AMD Radeon RX 9070 XT (16GB), Ryzen 7950X, 32GB RAM
\end{itemize}

Software environment: Windows 11, Vulkan SDK 1.3.x, DXR via DirectX 12. All drivers updated to latest stable versions. Power settings configured for maximum performance with adequate cooling to prevent thermal throttling.

\subsection{Instrumentation and Data Collection}
\label{subsec:instrumentation}

GPU timings are collected using timestamp queries inserted at key pipeline stages:

\begin{enumerate}
    \item Rasterization pass (G-buffer generation)
    \item Shadow ray tracing dispatch
    \item Reflection ray tracing dispatch
    \item Denoising pass
    \item Post-processing and final composite
\end{enumerate}

Each configuration executes for 120 consecutive frames following a 60-frame warm-up period to ensure thermal and workload stability. The middle 60 frames are analyzed to exclude transients. Each test repeats three times to measure variance and compute confidence intervals.

Metrics recorded per frame include:
\begin{itemize}
    \item Total frame time (ms)
    \item Per-stage GPU time (ms)
    \item GPU temperature and power draw (via nvidia-smi / AMD metrics)
    \item Ray count and average traversal depth (when available via profiler APIs)
\end{itemize}

Image buffers (final color, G-buffer components, motion vectors, depth) are captured for all test configurations to enable offline quality analysis.

\subsection{Image Quality Evaluation}
\label{subsec:quality-eval}

Perceptual quality is evaluated against path-traced ground truth using three complementary metrics:

\textbf{LPIPS (Learned Perceptual Image Patch Similarity):} Primary metric for perceptual quality, computed using the pretrained AlexNet-based model from Zhang et al. Lower values indicate higher perceptual similarity.

\textbf{SSIM (Structural Similarity Index):} Measures structural information preservation. Computed over 11×11 windows with standard parameters.

\textbf{PSNR (Peak Signal-to-Noise Ratio):} Traditional pixel-wise difference metric, included for completeness and comparison with prior work.

Temporal stability is measured by computing frame-to-frame LPIPS differences along the camera path, detecting flickering and ghosting artifacts.

Additionally, A/B visual comparison tests are conducted where observers rate perceived quality differences between configurations on a 5-point scale, validating that metric-based conclusions align with subjective perception.

\subsection{Quality-Per-Millisecond Metric}
\label{subsec:qpm-metric}

To directly compare configurations with different performance and quality characteristics, we derive a quality-per-millisecond (QPM) metric:

\begin{equation}
\text{QPM} = \frac{\text{Normalized Quality Gain}}{\text{RT Overhead (ms)}}
\end{equation}

where Normalized Quality Gain is defined as:

\begin{equation}
\text{NQG} = 1 - \frac{\text{LPIPS}_{\text{config}}}{\text{LPIPS}_{\text{raster}}}
\end{equation}

This metric quantifies the perceptual improvement per millisecond of ray tracing cost, enabling direct comparison across diverse configurations. Higher QPM indicates more efficient quality gains.

\subsection{Data Analysis}
\label{subsec:data-analysis}

For each configuration, we compute mean, median, and 90th percentile (P90) frame times per pipeline stage. Data is aggregated into CSV logs for batch processing and statistical analysis.

The following visualizations are generated:
\begin{itemize}
    \item Stacked bar charts showing frame time breakdown by rendering stage
    \item Line plots of RT cost vs. resolution scaling
    \item Scatter plots of RT cost vs. triangle count (scene complexity)
    \item Quality-cost scatter plots (LPIPS/SSIM vs. ms) with Pareto frontier highlighting
    \item Heatmaps showing quality-per-millisecond across sampling rates and hybrid strategies
\end{itemize}

Vulkan and DXR implementations are compared directly using identical scene data, shaders (translated via SPIR-V Cross), and timing methodology to isolate API-level performance differences.

Statistical significance of performance differences is assessed using paired t-tests with Bonferroni correction for multiple comparisons. Effect sizes are reported using Cohen's d to distinguish practically significant differences from merely statistically significant ones.

\section{Expected Results}
\label{sec:expected-results}

Based on preliminary profiling and hypothesis formulation, we anticipate the following outcomes:

\textbf{Performance Costs:} Ray-traced shadows will add approximately 2ms per light at 1080p, while reflections will cost 4-6ms depending on material roughness distribution. Combined, we expect 7-9ms overhead, slightly less than the sum due to shared BVH traversal setup costs.

\textbf{Resolution Scaling:} The transition from 1080p to 1440p is expected to increase ray tracing costs by approximately 1.8× due to the 1.77× increase in pixel count plus reduced ray coherence. The 1440p to 4K transition will incur a steeper 2.2× cost increase.

\textbf{Quality Optimization:} We expect 1 SPP with temporal denoising to achieve LPIPS scores within 10\% of 4 SPP raw while costing 75\% less, validating the effectiveness of temporal accumulation. Adaptive sampling should reduce costs by 40-60\% with minimal (< 5\%) quality degradation.

\textbf{API Parity:} Vulkan and DXR are expected to perform within ±5-10\% on identical workloads, with Vulkan potentially showing slight advantages in CPU-limited scenarios due to lower driver overhead and explicit synchronization control.

\textbf{Hybrid Strategy Ranking:} G-buffer-guided tracing with 1 SPP and temporal denoising is predicted to achieve the highest QPM score, offering approximately 50\% cost reduction compared to full-screen tracing with less than 10\% quality loss.

% Placeholder for results figures
% \begin{figure}[t]
% \centering
% \includegraphics[width=\columnwidth]{figures/performance_breakdown.pdf}
% \caption{Expected frame time breakdown showing incremental RT costs}
% \label{fig:perf-breakdown}
% \end{figure}

\section{Discussion}
\label{sec:discussion}

% This section will interpret results in context of hypotheses
% and provide practical recommendations

\section{Limitations}
\label{sec:limitations}

Our study focuses on shadows and reflections, excluding global illumination and ambient occlusion which have different performance characteristics. The three test scenes, while representative, cannot capture all possible scene types and characteristics. Hardware testing is limited to NVIDIA RTX and AMD RDNA architectures; results may not generalize to future GPU generations or alternative vendors.

The perceptual quality metrics, while validated in prior work, represent a specific model of human perception. Individual subjective preferences may vary, particularly for temporal artifacts where LPIPS may not fully capture discomfort from flickering or ghosting.

\section{Conclusion}
\label{sec:conclusion}

% Summary of findings and practical recommendations
% for incremental ray tracing adoption

\section{Future Work}
\label{sec:future-work}

Future research directions include extending this analysis to global illumination and ambient occlusion, evaluating next-generation denoising techniques (including ML-based approaches), and investigating dynamic quality scaling systems that adjust ray tracing configurations based on GPU load and frame time targets.

\bibliographystyle{plain}
\bibliography{references}

\end{document}